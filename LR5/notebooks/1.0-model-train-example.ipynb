{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7ajN74XGqZY"
   },
   "source": [
    "# MLP в pytorch\n",
    "\n",
    "## Работа №2\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "ФИО: Дмитрив Андрей Глебович\n",
    "\n",
    "---\n",
    "\n",
    "Далее в ноутбуке будут пропущенны части кода с комментариями о том что необходимо написать. А также текстовые ячейки с вопросами, на которые вам необходимо дать ответы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:14.556146Z",
     "start_time": "2024-12-12T23:27:14.529836Z"
    },
    "id": "7GNIoiJGKx2w"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Настройки для графиков\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYTqVFF9LGGW"
   },
   "source": [
    "**Совет по работе**\n",
    "\n",
    "Создавайте отдельные ячейки для ваших экспериментов. Пробуйте создавать небольшие тензоры и экспериментировать с ними, чтобы понять как работает та или иная функция и какие размерности данных вам требуются.\n",
    "\n",
    "Когда дойдете до цикла обучения сначала пробуйте работать с одной эпохой и ограниченным набором пакетов данных, чтобы меньше времени ожидать до обнаружения ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXVjctUHSBKP"
   },
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Из встроенных датасетов torchvision загрузите тестовую и обучающую выборки из EMNIST часть (split) Balanced или Letters, указав приобразование для изображений используя ToTensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:14.741605Z",
     "start_time": "2024-12-12T23:27:14.607126Z"
    },
    "id": "HJFO-KicGor8"
   },
   "outputs": [],
   "source": [
    "# Загрузка обучающей и тестовой выборки\n",
    "import os\n",
    "\n",
    "dir = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "train = os.path.join(dir, 'train')\n",
    "test = os.path.join(dir, 'test')\n",
    "\n",
    "train_set = datasets.EMNIST(\n",
    "    root=train,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    split='letters',\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_set = datasets.EMNIST(\n",
    "    root=test,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    split='letters',\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ6cYQa7NNdz"
   },
   "source": [
    "Выведите информацию о количестве данных в обеих выборках, размерностях изображений, количестве классов и сами метки классов.\n",
    "\n",
    "Функция `dir()` в python возвращает список допустимых атрибутов объекта, что может вам подсказать как получить часть информации о датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:14.751130Z",
     "start_time": "2024-12-12T23:27:14.745385Z"
    },
    "id": "Dk1iISsaNnRH"
   },
   "outputs": [],
   "source": [
    "train_samples_len = train_set.data.shape[0]\n",
    "test_samples_len = test_set.data.shape[0]\n",
    "image_shape = tuple(train_set.data[0].shape)\n",
    "classes_len = len(train_set.classes)\n",
    "classes_labels = train_set.classes\n",
    "\n",
    "print(train_samples_len, test_samples_len, image_shape, classes_len, classes_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atoBJNwMR56K"
   },
   "source": [
    "## Визуализация 9 случайных образцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:15.318733Z",
     "start_time": "2024-12-12T23:27:14.753896Z"
    },
    "id": "rNrmUjxpOfAg"
   },
   "outputs": [],
   "source": [
    "labels_map = dict(zip(range(len(train_set.classes)), train_set.classes))\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KV1aTiiSL6g"
   },
   "source": [
    "**По представленным образцам, что вы можете сказать о них? Есть ли в них что-то необычное и это усложнит или упростит обучение модели?** (макс. 5 баллов)\n",
    "\n",
    "Ваш ответ:\n",
    "- буквы имеют разный рукописный \"шрифт\"\n",
    "- буквы имеют различную ориентацию (наклон/поворот)\n",
    "- буквы имеют разную резкость контура. Где-то контур более четкий (m) где-то более размытый (z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Af2RGhdtS5Sn"
   },
   "source": [
    "## Создание загрузчиков данных (DataLoader)\n",
    "\n",
    "Данные при обучении модели редко передаются по одному образцу или все разом, обычно образцы объединяются в пакеты (batches) и уже они передаются на вход модели.\n",
    "\n",
    "Размер пакета (batch size) часто выбирается как $2^n$ (16, 32, 64, 128) и часто это зависит от доступной памяти.\n",
    "\n",
    "Загрузчики данных будут использоваться при обучении и тестировании модели и когда все пакеты были перебраны в датасете, это считается одной эпохой обучения. Чтобы между эпохами модель на обучалась на одинаковых пакетах их перемешивают (shuffle). При тестировании это не имеете разницы.\n",
    "\n",
    "Поэтому выберите один из размеров пакета при создании загрузчиков и для обучающего загрузчика используйте перемешивание, а тестового нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T00:35:12.695454Z",
     "start_time": "2024-12-13T00:35:12.690620Z"
    },
    "id": "X2bf-p21S9KB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2 ** 4 # Ваш код\n",
    "# batch_size = 2 ** 7 # Ваш код\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6MhOraTVjmO"
   },
   "source": [
    "**Опишите размерности данных одного пакета.** (макс. 10 баллов)\n",
    "\n",
    "Ваш ответ: (16, 1, 28, 28) (batch_size, channels, height, width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVSEAJ10WtyU"
   },
   "source": [
    "## Многослойный перцептрон\n",
    "\n",
    "В этой работе мы еще не будем использовать все возможности pytorch по построению нейронной сети например `nn.Sequential` или `nn.Module`, это будет рассмотрено в следующем задании.\n",
    "\n",
    "Ваша задача в этой работе используя функции из модуля `torch.nn.functional` `linear` и `relu`собрать цепочку вычислений для получения выходных значений. Во входном слое не забудьте использовать для изображений `.flatten()`. Чтобы вы могли использовать батчи, вам надо подумать какую часть тензора требуется сделать \"плоской\".\n",
    "\n",
    "Вывод с последнего слоя преобразуйте с помощью Softmax.\n",
    "\n",
    "Перед тем как использовать функцию потерь от значений из Softmax возьмите логарифм (`log()`) В качестве функции потерь используйте negative log likelihood loss `nll`. Почитайте какие данные ей требуются на вход, Вам придется самостоятельно подготовить тензор с помощью `F.one_hot()`.\n",
    "\n",
    "Параметры для функций, которые будут оптимизироваться, вы создаете самостоятельно с помощью `xavier_normal`, а отклонения (bias)\n",
    "с помощью `torch.randn()` с нужными размерностями.\n",
    "\n",
    "Не забывайте, что для использования `backward()`, у оптимизируемых параметров должен быть поднят флаг requires_grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:15.342313Z",
     "start_time": "2024-12-12T23:27:15.337009Z"
    },
    "id": "mNe-EEh1zoNL"
   },
   "outputs": [],
   "source": [
    "def xavier_normal(F_in, F_out):\n",
    "    limit = np.sqrt(6 / float(F_in + F_out))\n",
    "    W = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))\n",
    "    return torch.from_numpy(W).type(torch.float32).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:15.351675Z",
     "start_time": "2024-12-12T23:27:15.344714Z"
    },
    "id": "5kDfPxwSiS1H"
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import *\n",
    "input_size = 28 * 28 \n",
    "hidden_size = 128\n",
    "output_size = classes_len\n",
    "\n",
    "\n",
    "# Инициализация параметров\n",
    "w1 = xavier_normal(hidden_size, input_size)\n",
    "b1 = torch.randn(hidden_size, requires_grad=True)\n",
    "\n",
    "w2 = xavier_normal(output_size, hidden_size)\n",
    "b2 = torch.randn(output_size, requires_grad=True)\n",
    "\n",
    "# Функция прямого прохода\n",
    "def forward(x):\n",
    "    x = x.flatten(start_dim=1)  # преобразование тензора в плоский\n",
    "    z1 = linear(x, w1, b1)   # линейное преобразование\n",
    "    a1 = relu(z1)            # ф. актив. ReLU\n",
    "    z2 = linear(a1, w2, b2)\n",
    "    return log_softmax(z2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HYCJl-P33i5"
   },
   "source": [
    "**Опишите идею инициализации Ксавье. Почему могут быть проблемы с использованием torch.randn()?** (макс. 5 баллов)\n",
    "\n",
    "Ваш ответ:\n",
    "\n",
    "**Сколько параметров в вашей модели?** (макс. 5 баллов)\n",
    "\n",
    "Ваш ответ: \n",
    "- 28 * 28 (входной слой) * 128 (скрытый слой) + 128 (биасы) = 100_480 - первый слой\n",
    "- 128 * 26 (выходной слой) + 26 (биасы) 3_354\n",
    "\n",
    "Итого: 100_480 + 3_354 = 103_834"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APbrMAeW0EbD"
   },
   "source": [
    "Обновите параметры модели. Для обновления параметров не забудьте использовать контекст torch.no_grad(). Скорость обучения (lr) для начала можно взять равным 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:27:15.357520Z",
     "start_time": "2024-12-12T23:27:15.353406Z"
    },
    "id": "236_TPQF0Kbt"
   },
   "outputs": [],
   "source": [
    "# w -= w.grad * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-3ze7T10O12"
   },
   "source": [
    "**Что произойдет если не использовать этот контекст?** (макс. 5 баллов)\n",
    "\n",
    "Ваш ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsDwKtmmjO2k"
   },
   "source": [
    "## Цикл обучения\n",
    "\n",
    "Напишите цикл, который за заданное количество эпох оптимизирует параметры вашей модели.\n",
    "\n",
    "1. Делается прямой проход и получаются значения работы вашей модели.\n",
    "1. Рассчитывается значение потерь.\n",
    "1. Расчитываются градиенты.\n",
    "1. Обновляются параметры с учетом скорости обучения.\n",
    "\n",
    "Каждые 100 пройденных батчей выводите значение потерь `loss.item()`.\n",
    "\n",
    "Также в рамках каждой эпохи оценивайте потери и точность работы вашей модели.\n",
    "\n",
    "Для подсчета количества правильных предсказаний можно использовать следующий код внутри цикла:\n",
    "\n",
    "```python\n",
    "correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "```\n",
    "\n",
    "...и снаружи цикла:\n",
    "\n",
    "```python\n",
    "correct /= len(dataloader.dataset)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T00:36:31.130084Z",
     "start_time": "2024-12-13T00:35:19.956688Z"
    },
    "id": "H2363yRRpykr"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.001  # 1e-3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
    "        # Прямой проход\n",
    "        y_pred = forward(x)\n",
    "        loss = nll_loss(y_pred, y)\n",
    "\n",
    "        # Обратное распространение\n",
    "        loss.backward()\n",
    "\n",
    "        # Обновление параметров\n",
    "        with torch.no_grad():\n",
    "            w1 -= learning_rate * w1.grad\n",
    "            b1 -= learning_rate * b1.grad\n",
    "            w2 -= learning_rate * w2.grad\n",
    "            b2 -= learning_rate * b2.grad\n",
    "\n",
    "            # Сброс градиентов\n",
    "            w1.grad.zero_()\n",
    "            b1.grad.zero_()\n",
    "            w2.grad.zero_()\n",
    "            b2.grad.zero_()\n",
    "\n",
    "        correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(f\"e: {epoch + 1}/{epochs}, b: {batch_idx}/{len(train_dataloader)}, l: {round(loss.item(), 3)}\")\n",
    "            \n",
    "    accuracy = correct / len(train_dataloader.dataset)\n",
    "    print('accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go0MUsTD3u2x"
   },
   "source": [
    "**Какова точность работы вашей модели?** (макс. 30 баллов)\n",
    "\n",
    "Ваш ответ: \n",
    "\n",
    "\n",
    "Кол-во эпох: 10,\n",
    "Скорость обучения: 0.001,\n",
    "Точность: 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Up0yYme3lIi"
   },
   "source": [
    "## Подбор гиперпараметров\n",
    "\n",
    "Теперь когда у вас есть рабочый код для модели и ее обучения, попробуйте разные варианты скорости обучения, количества параметров в скрытых слоя модели, количества эпох, размера батчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:46:32.988311Z",
     "start_time": "2024-12-12T23:46:32.981025Z"
    },
    "id": "62ZM8krd4sq3"
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import *\n",
    "\n",
    "def test(epochs, learning_rate):\n",
    "    # Инициализация параметров\n",
    "    w1 = xavier_normal(hidden_size, input_size)\n",
    "    b1 = torch.randn(hidden_size, requires_grad=True)\n",
    "    \n",
    "    w2 = xavier_normal(output_size, hidden_size)\n",
    "    b2 = torch.randn(output_size, requires_grad=True)\n",
    "    \n",
    "    # Функция прямого прохода\n",
    "    def forward(x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        z1 = linear(x, w1, b1)\n",
    "        a1 = relu(z1)\n",
    "        z2 = linear(a1, w2, b2)\n",
    "        log_probs = log_softmax(z2, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "    correct = 0\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        for batch_idx, (x, y) in enumerate(train_dataloader):\n",
    "            # Прямой проход\n",
    "            y_pred = forward(x)\n",
    "            loss = nll_loss(y_pred, y)\n",
    "    \n",
    "            # Обратное распространение\n",
    "            loss.backward()\n",
    "    \n",
    "            # Обновление параметров\n",
    "            with torch.no_grad():\n",
    "                w1 -= learning_rate * w1.grad\n",
    "                b1 -= learning_rate * b1.grad\n",
    "                w2 -= learning_rate * w2.grad\n",
    "                b2 -= learning_rate * b2.grad\n",
    "    \n",
    "                # Сброс градиентов\n",
    "                w1.grad.zero_()\n",
    "                b1.grad.zero_()\n",
    "                w2.grad.zero_()\n",
    "                b2.grad.zero_()\n",
    "    \n",
    "            correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        print(f\"{epoch + 1} / {epochs}\")\n",
    "    return correct / len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vSoXjNt4xB8"
   },
   "source": [
    "**Сколько комбинаций гиперпараметров вы попробовали? Напишите их и точности, которые были при них получены.** (макс. 40 баллов)\n",
    "\n",
    "Ваш ответ: 8 комбинаций.\n",
    "\n",
    "| **№** | **epoch** | **learning_rate** | **accuracy** |\n",
    "|:-----:|:---------:|:-----------------:|:------------:|\n",
    "|   1   |     5     |        0.02       |     0.877    |\n",
    "|   2   |     10    |        0.01       |     0.882    |\n",
    "|   3   |     5     |        0.05       |     0.893    |\n",
    "|   4   |     5     |        0.08       |     0.892    |\n",
    "|   5   |     5     |        0.1        |     0.888    |\n",
    "|   6   |     10    |        0.1        |     0.905    |\n",
    "|   7   |     15    |        0.5        |     0.820    |\n",
    "|   8   |     30    |       0.001       |     0.824    |\n",
    "\n",
    "\n",
    "Наиболее высокая точность у эксперимента №6 - 90% (10 эпох, learning_rate 0.1)\n",
    "Самый худший результат показал эксперимент №7 - 82% (15 эпох, learning_rate 0.5)\n",
    "Также плохой результат показал эксперимент №8 - 82% (30 эпох, learning_rate 0.5)\n",
    "\n",
    "Можно сделать вывод, что многократное повторение одной и той же обучающей выборки не приводит к повышению точности модели.\n",
    "Текущая серия экспериментов показала, что оптимальным является небольшое количество эпох с умеренным шагом обучения.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:47:42.368437Z",
     "start_time": "2024-12-12T23:46:39.376837Z"
    }
   },
   "outputs": [],
   "source": [
    "test(5, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:50:46.309672Z",
     "start_time": "2024-12-12T23:47:48.193614Z"
    }
   },
   "outputs": [],
   "source": [
    "test(10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:52:25.398602Z",
     "start_time": "2024-12-12T23:51:37.538991Z"
    },
    "id": "GXlEiDOACTTF"
   },
   "outputs": [],
   "source": [
    "test(5, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:53:44.998468Z",
     "start_time": "2024-12-12T23:52:52.178672Z"
    }
   },
   "outputs": [],
   "source": [
    "test(5, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:57:45.031932Z",
     "start_time": "2024-12-12T23:56:35.609101Z"
    }
   },
   "outputs": [],
   "source": [
    "test(5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:56:24.583989Z",
     "start_time": "2024-12-12T23:54:45.732567Z"
    }
   },
   "outputs": [],
   "source": [
    "test(10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T00:03:20.962099Z",
     "start_time": "2024-12-13T00:00:32.248471Z"
    }
   },
   "outputs": [],
   "source": [
    "test(15, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T00:09:26.247536Z",
     "start_time": "2024-12-13T00:05:19.496429Z"
    }
   },
   "outputs": [],
   "source": [
    "    test(30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
